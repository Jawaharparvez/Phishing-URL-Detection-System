{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1lLF9lCeiFZyrJqqmGb4FVKS0ZCQD1Dq0?authuser=7#scrollTo=d53masJcsMmi\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "\n",
        "\n",
        "### *You can open and run this notebook in Google Colab by clicking the badge above.*"
      ],
      "metadata": {
        "id": "kUgZUredqIzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Phishing URL Detector\n",
        "*This notebook provides a basic phishing URL detector using either a rule-based or machine learning approach.*\n"
      ],
      "metadata": {
        "id": "3KzbQ6IYlqIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Step 1: Install Required Libraries*"
      ],
      "metadata": {
        "id": "SPxqvx24q8l5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "a_ysuX5klmCv"
      },
      "outputs": [],
      "source": [
        "!pip install tldextract"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Step 2: Import Required Libraries*\n",
        "\n",
        "“Here, we import all the necessary Python libraries used throughout the notebook. These include:\n",
        "* Standard libraries for URL parsing, regular expressions, and networking.\n",
        "* `tldextract` for URL decomposition.\n",
        "* `sklearn`, `joblib`, and `numpy` for optional machine learning functionality.\n",
        "* `os` for file checks and path handling.”\n"
      ],
      "metadata": {
        "id": "YjuH4dwDrFn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import urllib.parse\n",
        "import tldextract\n",
        "import socket\n",
        "import ssl\n",
        "from datetime import datetime\n",
        "from urllib.request import urlopen\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os"
      ],
      "metadata": {
        "id": "5OGdALkNrO_k"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Step 3: Phishing Detector Class Definition*\n",
        "“The `SimplePhishingDetector` class is defined here and includes:\n",
        "* **Initialization logic** to either load a pre-trained machine learning model or fall back to a rule-based detection system.\n",
        "* **URL analysis** that extracts features, applies rule-based or ML-based classification, and returns a phishing verdict along with confidence and reasons.\n",
        "* **Feature extraction** functions to parse a URL and identify suspicious traits.\n",
        "* **Rule-based heuristics** for identifying phishing patterns.\n",
        "* **Utility functions** for checking domain existence, SSL certificates, and converting features for ML use.”"
      ],
      "metadata": {
        "id": "F3t-kAGaNt07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimplePhishingDetector:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the phishing detector with a pre-trained model or a basic rule-based system\"\"\"\n",
        "        # Try to load a pre-trained model if available\n",
        "        self.model_file = \"phishing_model.joblib\"\n",
        "        if os.path.exists(self.model_file):\n",
        "            self.model = joblib.load(self.model_file)\n",
        "            self.use_ml = True\n",
        "            print(\"Loaded pre-trained model\")\n",
        "        else:\n",
        "            # No model available, use rule-based detection\n",
        "            self.use_ml = False\n",
        "            print(\"Using rule-based detection (no model found)\")\n",
        "\n",
        "    def analyze_url(self, url):\n",
        "        \"\"\"Analyze a URL and determine if it's likely a phishing attempt\"\"\"\n",
        "        # Ensure URL has a scheme\n",
        "        if not url.startswith(('http://', 'https://')):\n",
        "            url = 'http://' + url\n",
        "\n",
        "        # Extract features\n",
        "        features = self._extract_basic_features(url)\n",
        "\n",
        "        if self.use_ml:\n",
        "            # Use the model for prediction\n",
        "            feature_vector = self._convert_features_to_vector(features)\n",
        "            prediction = self.model.predict([feature_vector])[0]\n",
        "            probability = self.model.predict_proba([feature_vector])[0][1]\n",
        "\n",
        "            return {\n",
        "                'url': url,\n",
        "                'is_phishing': bool(prediction),\n",
        "                'confidence': probability,\n",
        "                'reasons': self._get_risk_factors(features)\n",
        "            }\n",
        "        else:\n",
        "            # Use rule-based system\n",
        "            is_phishing, score, reasons = self._rule_based_detection(features)\n",
        "\n",
        "            return {\n",
        "                'url': url,\n",
        "                'is_phishing': is_phishing,\n",
        "                'confidence': score,\n",
        "                'reasons': reasons\n",
        "            }\n",
        "\n",
        "    def _extract_basic_features(self, url):\n",
        "        \"\"\"Extract basic features from a URL\"\"\"\n",
        "        features = {}\n",
        "\n",
        "        # Parse the URL\n",
        "        parsed_url = urllib.parse.urlparse(url)\n",
        "        extract_result = tldextract.extract(url)\n",
        "\n",
        "        # Basic URL information\n",
        "        features['url'] = url\n",
        "        features['domain'] = parsed_url.netloc\n",
        "        features['scheme'] = parsed_url.scheme\n",
        "        features['path'] = parsed_url.path\n",
        "        features['query'] = parsed_url.query\n",
        "        features['subdomain'] = extract_result.subdomain\n",
        "        features['registered_domain'] = extract_result.registered_domain\n",
        "        features['tld'] = extract_result.suffix\n",
        "\n",
        "        # Basic URL properties\n",
        "        features['url_length'] = len(url)\n",
        "        features['domain_length'] = len(parsed_url.netloc)\n",
        "        features['path_length'] = len(parsed_url.path)\n",
        "        features['query_length'] = len(parsed_url.query)\n",
        "        features['subdomain_count'] = len(extract_result.subdomain.split('.')) if extract_result.subdomain else 0\n",
        "\n",
        "        # Suspicious character patterns\n",
        "        features['has_ip_address'] = 1 if self._has_ip_address(url) else 0\n",
        "        features['has_at_symbol'] = 1 if '@' in url else 0\n",
        "        features['has_double_slash'] = 1 if '//' in parsed_url.path else 0\n",
        "        features['has_hex_chars'] = 1 if re.search(r'%[0-9a-fA-F]{2}', url) else 0\n",
        "        features['has_https'] = 1 if parsed_url.scheme == 'https' else 0\n",
        "\n",
        "        # Count special characters\n",
        "        features['hyphen_count'] = url.count('-')\n",
        "        features['underscore_count'] = url.count('_')\n",
        "        features['slash_count'] = url.count('/')\n",
        "        features['dot_count'] = url.count('.')\n",
        "        features['equal_count'] = url.count('=')\n",
        "        features['question_mark_count'] = url.count('?')\n",
        "        features['ampersand_count'] = url.count('&')\n",
        "        features['percent_count'] = url.count('%')\n",
        "\n",
        "        # Check for brand names in domain (common in phishing)\n",
        "        common_brands = ['paypal', 'apple', 'amazon', 'microsoft', 'google', 'facebook',\n",
        "                         'ebay', 'instagram', 'chase', 'bank', 'netflix', 'linkedin',\n",
        "                         'twitter', 'yahoo', 'blockchain', 'coinbase', 'gmail']\n",
        "\n",
        "        for brand in common_brands:\n",
        "            if brand in parsed_url.netloc.lower() and brand not in extract_result.domain.lower():\n",
        "                features['brand_in_subdomain'] = 1\n",
        "                features['targeted_brand'] = brand\n",
        "                break\n",
        "        else:\n",
        "            features['brand_in_subdomain'] = 0\n",
        "            features['targeted_brand'] = None\n",
        "\n",
        "        # Try to check domain age (simplified)\n",
        "        features['domain_exists'] = self._check_domain_exists(parsed_url.netloc)\n",
        "\n",
        "        # Check for SSL certificate (simplified)\n",
        "        if parsed_url.scheme == 'https':\n",
        "            features['ssl_valid'] = self._check_ssl(parsed_url.netloc)\n",
        "        else:\n",
        "            features['ssl_valid'] = 0\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _has_ip_address(self, url):\n",
        "        \"\"\"Check if the URL contains an IP address\"\"\"\n",
        "        pattern = re.compile(r'(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])')\n",
        "        return bool(pattern.search(url))\n",
        "\n",
        "    def _check_domain_exists(self, domain):\n",
        "        \"\"\"Check if a domain resolves to an IP address\"\"\"\n",
        "        try:\n",
        "            socket.gethostbyname(domain)\n",
        "            return 1\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "    def _check_ssl(self, domain):\n",
        "        \"\"\"Check if SSL certificate is valid\"\"\"\n",
        "        try:\n",
        "            context = ssl.create_default_context()\n",
        "            with socket.create_connection((domain, 443), timeout=3) as sock:\n",
        "                with context.wrap_socket(sock, server_hostname=domain) as ssock:\n",
        "                    return 1\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "    def _rule_based_detection(self, features):\n",
        "        \"\"\"Simple rule-based phishing detection\"\"\"\n",
        "        risk_score = 0\n",
        "        reasons = []\n",
        "\n",
        "        # Check URL length (phishing URLs are often long)\n",
        "        if features['url_length'] > 100:\n",
        "            risk_score += 0.1\n",
        "            reasons.append(\"Unusually long URL\")\n",
        "\n",
        "        # Check for IP address in URL\n",
        "        if features['has_ip_address']:\n",
        "            risk_score += 0.2\n",
        "            reasons.append(\"Contains IP address instead of domain name\")\n",
        "\n",
        "        # Check for @, // symbols\n",
        "        if features['has_at_symbol']:\n",
        "            risk_score += 0.2\n",
        "            reasons.append(\"Contains @ symbol\")\n",
        "\n",
        "        if features['has_double_slash']:\n",
        "            risk_score += 0.1\n",
        "            reasons.append(\"Contains // in the path\")\n",
        "\n",
        "        # Check for hexadecimal characters\n",
        "        if features['has_hex_chars']:\n",
        "            risk_score += 0.1\n",
        "            reasons.append(\"Contains hexadecimal character codes\")\n",
        "\n",
        "        # Check for HTTPS\n",
        "        if not features['has_https']:\n",
        "            risk_score += 0.15\n",
        "            reasons.append(\"Not using HTTPS\")\n",
        "\n",
        "        # Check domain\n",
        "        if not features['domain_exists']:\n",
        "            risk_score += 0.2\n",
        "            reasons.append(\"Domain does not resolve to an IP address\")\n",
        "\n",
        "        # Check SSL certificate\n",
        "        if features['has_https'] and not features['ssl_valid']:\n",
        "            risk_score += 0.2\n",
        "            reasons.append(\"Invalid SSL certificate\")\n",
        "\n",
        "        # Check for brand names in domain\n",
        "        if features['brand_in_subdomain']:\n",
        "            risk_score += 0.2\n",
        "            reasons.append(f\"Contains brand name '{features['targeted_brand']}' but not in main domain\")\n",
        "\n",
        "        # Check for suspicious TLD\n",
        "        suspicious_tlds = ['tk', 'ml', 'ga', 'cf', 'gq', 'xyz']\n",
        "        if features['tld'] in suspicious_tlds:\n",
        "            risk_score += 0.1\n",
        "            reasons.append(f\"Uses suspicious TLD: .{features['tld']}\")\n",
        "\n",
        "        # Too many subdomains\n",
        "        if features['subdomain_count'] > 3:\n",
        "            risk_score += 0.1\n",
        "            reasons.append(\"Excessive number of subdomains\")\n",
        "\n",
        "        # Too many special characters\n",
        "        special_char_count = (features['hyphen_count'] + features['underscore_count'] +\n",
        "                              features['percent_count'])\n",
        "        if special_char_count > 10:\n",
        "            risk_score += 0.1\n",
        "            reasons.append(\"Excessive special characters\")\n",
        "\n",
        "        # Determine if it's likely phishing based on score\n",
        "        is_phishing = risk_score >= 0.3\n",
        "\n",
        "        return is_phishing, risk_score, reasons\n",
        "\n",
        "    def _convert_features_to_vector(self, features):\n",
        "        \"\"\"Convert features dictionary to a vector for ML model input\"\"\"\n",
        "        # This is a simplified version - a real implementation would match the training features\n",
        "        return [\n",
        "            features['url_length'],\n",
        "            features['domain_length'],\n",
        "            features['path_length'],\n",
        "            features['query_length'],\n",
        "            features['subdomain_count'],\n",
        "            features['has_ip_address'],\n",
        "            features['has_at_symbol'],\n",
        "            features['has_double_slash'],\n",
        "            features['has_hex_chars'],\n",
        "            features['has_https'],\n",
        "            features['hyphen_count'],\n",
        "            features['underscore_count'],\n",
        "            features['slash_count'],\n",
        "            features['dot_count'],\n",
        "            features['equal_count'],\n",
        "            features['question_mark_count'],\n",
        "            features['ampersand_count'],\n",
        "            features['percent_count'],\n",
        "            features['brand_in_subdomain'],\n",
        "            features['domain_exists'],\n",
        "            features['ssl_valid']\n",
        "        ]\n",
        "\n",
        "    def _get_risk_factors(self, features):\n",
        "        \"\"\"Get risk factors based on features (for ML-based detection)\"\"\"\n",
        "        reasons = []\n",
        "\n",
        "        if features['has_ip_address']:\n",
        "            reasons.append(\"Contains IP address instead of domain name\")\n",
        "\n",
        "        if features['has_at_symbol']:\n",
        "            reasons.append(\"Contains @ symbol\")\n",
        "\n",
        "        if features['has_double_slash']:\n",
        "            reasons.append(\"Contains // in the path\")\n",
        "\n",
        "        if features['has_hex_chars']:\n",
        "            reasons.append(\"Contains hexadecimal character codes\")\n",
        "\n",
        "        if not features['has_https']:\n",
        "            reasons.append(\"Not using HTTPS\")\n",
        "\n",
        "        if not features['domain_exists']:\n",
        "            reasons.append(\"Domain does not resolve to an IP address\")\n",
        "\n",
        "        if features['has_https'] and not features['ssl_valid']:\n",
        "            reasons.append(\"Invalid SSL certificate\")\n",
        "\n",
        "        if features['brand_in_subdomain']:\n",
        "            reasons.append(f\"Contains brand name '{features['targeted_brand']}' but not in main domain\")\n",
        "\n",
        "        if features['url_length'] > 100:\n",
        "            reasons.append(\"Unusually long URL\")\n",
        "\n",
        "        return reasons\n"
      ],
      "metadata": {
        "id": "hZ-l3VhxL2UO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Step 4: Main Detection Function*\n",
        "“This cell defines a `main()` function to interactively run the detector. It:\n",
        "* Prompts the user to input URLs.\n",
        "* Analyzes each URL using the `SimplePhishingDetector`.\n",
        "* Outputs whether the URL is legitimate or suspicious, including a confidence score and a breakdown of risk factors.”"
      ],
      "metadata": {
        "id": "pQ0zglYOMRFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main function to run the phishing detector from command line\"\"\"\n",
        "    print(\"\\n===== Simple Phishing URL Detector =====\\n\")\n",
        "\n",
        "    detector = SimplePhishingDetector()\n",
        "\n",
        "    while True:\n",
        "        url = input(\"\\nEnter a URL to check (or 'exit' to quit): \")\n",
        "\n",
        "        if url.lower() in ['exit', 'quit', 'q']:\n",
        "            break\n",
        "\n",
        "        if not url:\n",
        "            continue\n",
        "\n",
        "        print(\"\\nAnalyzing URL...\")\n",
        "        result = detector.analyze_url(url)\n",
        "\n",
        "        print(\"\\n----- Analysis Results -----\")\n",
        "        print(f\"URL: {result['url']}\")\n",
        "\n",
        "        if result['is_phishing']:\n",
        "            print(\"\\n⚠️  WARNING: This URL appears to be FRAUDULENT ⚠️\")\n",
        "            print(f\"Confidence: {result['confidence']:.2f}\")\n",
        "\n",
        "            if result['reasons']:\n",
        "                print(\"\\nSuspicious characteristics:\")\n",
        "                for i, reason in enumerate(result['reasons'], 1):\n",
        "                    print(f\"  {i}. {reason}\")\n",
        "        else:\n",
        "            print(\"\\n✓ This URL appears to be LEGITIMATE\")\n",
        "            print(f\"Confidence: {1-result['confidence']:.2f}\")\n",
        "\n",
        "            if result['reasons']:\n",
        "                print(\"\\nNote: The following minor issues were detected:\")\n",
        "                for i, reason in enumerate(result['reasons'], 1):\n",
        "                    print(f\"  {i}. {reason}\")\n",
        "\n",
        "        print(\"\\n-----------------------------\")"
      ],
      "metadata": {
        "id": "feL-EWnEL2R4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Step 5: Script Execution Trigger*\n",
        "This cell ensures that the main() function only runs when the script is executed directly (not when imported as a module). It provides a command-line interface for testing URLs within the notebook."
      ],
      "metadata": {
        "id": "UtSaoUQ0O13G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "khOWIhUcL2PS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}